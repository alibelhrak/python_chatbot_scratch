{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOEmRCxnReuNSHwmuXVv6II",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alibelhrak/python_chatbot_scratch/blob/main/Cha_bot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZcfYeU7NB21O",
        "outputId": "f4bcc97a-2199-4aa1-a4b3-b677b7689839"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Libraries"
      ],
      "metadata": {
        "id": "DGtDK_hq_dTk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q0zUFHN4-jlX"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense , Dropout   , Flatten\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.losses import categorical_crossentropy\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparing intentes"
      ],
      "metadata": {
        "id": "WFTtKoCy_nFI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "intents_data={\n",
        "  \"intents\": [\n",
        "    {\n",
        "      \"tag\": \"greeting\",\n",
        "      \"patterns\": [\"Hello\", \"Hi\", \"Hey\", \"What's up\", \"Good morning\"],\n",
        "      \"responses\": [\"Hello!\", \"Good day!\", \"Hey there!\", \"Hi! How can I assist you?\"]\n",
        "    },\n",
        "    {\n",
        "      \"tag\": \"goodbye\",\n",
        "      \"patterns\": [\"Bye\", \"Goodbye\", \"See you later\", \"Take care\"],\n",
        "      \"responses\": [\"Goodbye!\", \"See you soon!\", \"Take care!\", \"Have a great day!\"]\n",
        "    },\n",
        "    {\n",
        "      \"tag\": \"thanks\",\n",
        "      \"patterns\": [\"Thank you\", \"Thanks\", \"Appreciate it\"],\n",
        "      \"responses\": [\"You're welcome!\", \"Glad I could help!\", \"Anytime!\"]\n",
        "    },\n",
        "    {\n",
        "      \"tag\": \"help\",\n",
        "      \"patterns\": [\"Can you help me?\", \"I need assistance\", \"Help me\"],\n",
        "      \"responses\": [\"Sure! What do you need help with?\", \"I'm here to assist!\", \"Tell me what you need help with.\"]\n",
        "    },\n",
        "    {\n",
        "      \"tag\": \"weather\",\n",
        "      \"patterns\": [\"What's the weather like?\", \"Is it raining today?\", \"Tell me the forecast\"],\n",
        "      \"responses\": [\"I can check the weather for you!\", \"Do you want today's or this week's forecast?\", \"Let me get that info for you.\"]\n",
        "    },\n",
        "    {\n",
        "      \"tag\": \"joke\",\n",
        "      \"patterns\": [\"Tell me a joke\", \"Make me laugh\", \"Do you know any jokes?\"],\n",
        "      \"responses\": [\"Why don’t skeletons fight each other? They don’t have the guts!\", \"Why did the scarecrow win an award? Because he was outstanding in his field!\"]\n",
        "    }\n",
        "  ]\n",
        "}\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "AXbylGMR_q0J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt_tab')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vfuSRPsOLT41",
        "outputId": "c815bb1b-9df5-4221-c81b-f3cebf5a1254"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "words=[]\n",
        "classes=[]\n",
        "documents=[]\n",
        "ignore_symbols = ['.','?' , ';' , ':' , '!' , '%']\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "for intent in intents_data[\"intents\"]:\n",
        "    for pattern in intent[\"patterns\"]:\n",
        "        words_list = word_tokenize(pattern)\n",
        "        words.append(words_list)\n",
        "        documents.append((words_list, intent[\"tag\"]))\n",
        "\n",
        "        if intent[\"tag\"] not in classes:\n",
        "            classes.append(intent[\"tag\"])\n",
        "\n",
        "print(\"Documents:\", documents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gT9fQVjTCIbP",
        "outputId": "d896eb20-52ec-49ae-d45b-6b9201f6fa48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Documents: [(['Hello'], 'greeting'), (['Hi'], 'greeting'), (['Hey'], 'greeting'), (['What', \"'s\", 'up'], 'greeting'), (['Good', 'morning'], 'greeting'), (['Bye'], 'goodbye'), (['Goodbye'], 'goodbye'), (['See', 'you', 'later'], 'goodbye'), (['Take', 'care'], 'goodbye'), (['Thank', 'you'], 'thanks'), (['Thanks'], 'thanks'), (['Appreciate', 'it'], 'thanks'), (['Can', 'you', 'help', 'me', '?'], 'help'), (['I', 'need', 'assistance'], 'help'), (['Help', 'me'], 'help'), (['What', \"'s\", 'the', 'weather', 'like', '?'], 'weather'), (['Is', 'it', 'raining', 'today', '?'], 'weather'), (['Tell', 'me', 'the', 'forecast'], 'weather'), (['Tell', 'me', 'a', 'joke'], 'joke'), (['Make', 'me', 'laugh'], 'joke'), (['Do', 'you', 'know', 'any', 'jokes', '?'], 'joke')]\n"
          ]
        }
      ]
    }
  ]
}